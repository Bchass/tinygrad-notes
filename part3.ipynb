{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Three: combining CPU and GPU operations\n",
    "We would like to refactor and combine what we have in part 1 and 2 into a unified\n",
    "interface like pytorch, where you pass in a device type of either CPU or GPU and\n",
    "then the rest of the operations work automatically. In other words, we extract a\n",
    "shared representation between all the operations (addition, multiplication etc.)\n",
    "and all the device types (currently just CPU and GPU), this will take us to a minimal\n",
    "version of tinygrad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first change to make is upon Tensor initialization.\n",
    "\n",
    "Tensor data can be passed either GPU buffer or numpy array, it needs to detect it automatically, and able to convert it to the desired device.\n",
    "\n",
    "```python\n",
    "def __init__(self, data, shape, device):\n",
    "  self.device = device\n",
    "  self.data = _move_data(data, shape, device)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how _move_data can be implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "\n",
    "cl_ctx = cl.create_some_context(answers=[0,2])  # change if you don't have mac\n",
    "cl_queue = cl.CommandQueue(cl_ctx)\n",
    "\n",
    "def _move_data(data, shape, device):\n",
    "  if device == 'CPU':\n",
    "    if isinstance(data, list):\n",
    "      return np.array(data, dtype=np.float32)\n",
    "    elif isinstance(data, cl.Buffer):\n",
    "      ret = np.empty(shape, dtype=np.float32)\n",
    "      cl.enqueue_copy(cl_queue, data, ret)\n",
    "      return ret\n",
    "    elif isinstance(data, np.array):\n",
    "      return data\n",
    "  elif device == 'GPU':\n",
    "    if isinstance(data, list):\n",
    "      ret = cl.Buffer(cl_ctx, cl.mem_flags.WRITE_ONLY, 4 * len(list))\n",
    "      return ret\n",
    "    elif isinstance(data, cl.Buffer):\n",
    "      return data\n",
    "    elif isinstance(data, np.array):\n",
    "      ret = cl.Buffer(cl_ctx, cl.mem_flags.WRITE_ONLY, hostbuf=data)\n",
    "      return ret\n",
    "    \n",
    "\n",
    "a = np.array([2], dtype=np.float32)\n",
    "a = cl.Buffer(cl_ctx, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=a)\n",
    "ret = _move_data(a, (1,), \"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second change to make is always initialize the gradient as zero, and add the attribute on whether the tensor should require gradient\n",
    "```python\n",
    "def __init__(self, requires_grad=True)\n",
    "  self.grad = None\n",
    "  self.requires_grad = requires_grad\n",
    "```\n",
    "\n",
    "We now think about what happens when a tensor that requires grad is multiplied with another, the output tensor inherits the require_grad attribute of the input tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next change is to abstract the algebraic operations, if you look at part 2 and part 1, the implementation for multiplication and addition are actually very similar on different axes: between GPU and CPU, between autograd and no-grad, between mulplication and addition. In tinygrad, all these operations are boiled down to a dispatch call, that has arguments shifted around for the above 6 sub-scenarios. \n",
    "\n",
    "To do that, we look at what's similar between __add__ and __mul__. First, it's a binary operation. So it can be represented as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_op_cpu(op, x, y):\n",
    "  if op == 'ADD':\n",
    "    ret = x + y\n",
    "  elif op == 'MUL':\n",
    "    ret = x * y\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are a bit more complicated in the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_op_gpu(op, x, y, ret):\n",
    "  if op == 'ADD':\n",
    "    code = '+'\n",
    "  elif op == 'MUL':\n",
    "    code = '*'\n",
    "\n",
    "  prg = cl.Program(cl_ctx, f\"\"\"\n",
    "      __kernel void binary_op(\n",
    "          __global const float *a_g, __global const float *b_g, __global float *res_g)\n",
    "      {{\n",
    "      int gid = get_global_id(0);\n",
    "      res_g[gid] = a_g[gid] {code} b_g[gid];\n",
    "      }}\n",
    "      \"\"\").build()\n",
    "  prg.binary_op(cl_queue, [ret.size//4], None, x, y, ret)\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is how to actually define the __mul__ and __add__ on the tensor. We want the tensor to have these two methods and when called, automatically call the correct binary_op after checking the device type. We also don't want to keep writing __mul__, __add__, __div__ and so on as actual method, but rather run in a loop to register them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "  pass\n",
    "\n",
    "def dispatch(x, y):\n",
    "  device = x.device\n",
    "  requires_grad = any([t.requires_grad for t in [x, y]])\n",
    "  if device == 'CPU':\n",
    "    ret = binary_op_cpu(x.data, y.data)\n",
    "  elif device == 'GPU':\n",
    "    ret = cl.Buffer(cl_ctx, cl.mem_flags.WRITE_ONLY, 4)\n",
    "    ret = binary_op_gpu(x.data, y.data, ret)\n",
    "  return Tensor(ret, requires_grad)\n",
    "ops = [\"__add__\", \"__mul__\"]\n",
    "for op in ops:\n",
    "  setattr(Tensor, op, dispatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplifies a lot of boilerplate code, despite adding some complexity, but given we may have way more than 2 operations, the overhead is well worth it. \n",
    "\n",
    "Let's not forget we also need to keep track of the calculation graph for backward pass if the operation is done on the Tensor of interest, and not keep such info if it's a gradient Tensor or something with requires_grad set to False intentionally. So we need an extra layer of abstraction between Tensor and ops. This layer would have the backward method on it. \n",
    "\n",
    "The concept is that we create an object that stores information necessary for back propogation, and if the Tensor does not \n",
    "require grad, then we discard this object. And in the subsequent backward call, we terminate if we do not see this object.\n",
    "\n",
    "To start, dispatch will just call this middle layer:\n",
    "```python\n",
    "def dispatch(x, y):\n",
    "  return fxn.apply(x, y)\n",
    "```\n",
    "\n",
    "and fxn is the middle layer class. It has a shared base class called `Function`, and the variant for `Add` and `Mul`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function:\n",
    "  def __init__(self, device, requires_grad, x, y):\n",
    "    self.device = device\n",
    "    self.requires_grad = requires_grad\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "  @classmethod\n",
    "  def apply(cls, x, y):\n",
    "    device = x.device\n",
    "    requires_grad = x.requires_grad\n",
    "    ctx = cls(device, requires_grad, x, y)\n",
    "    ret_data = ctx.forward(ctx, x, y)\n",
    "    ret = Tensor(ret_data, device, requires_grad)\n",
    "    ret._ctx = ctx\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took me a while to figure out this inversion of control. The awkwardness at first glance is to extract a unified interface for as many operations as possible. Let's next actually define the child class, namely it will have the `forward` and `backward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul(Function):\n",
    "  def forward(ctx, x, y):\n",
    "    ctx.save_for_backward(x, y)\n",
    "    ctx.binary_op('MUL', x, y)\n",
    "\n",
    "  def backward(ctx, grad_output):\n",
    "    x,y = ctx.saved_tensors\n",
    "    tmp = ctx.buffer(grad_output.shape)\n",
    "    # skipping for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the base class need two more methods to save the tensor. Let's just see the full code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function:\n",
    "  def __init__(self, device, requires_grad, x, y):\n",
    "    self.device = device\n",
    "    self.requires_grad = requires_grad\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.saved_tensors = []\n",
    "\n",
    "  @classmethod\n",
    "  def apply(cls, x, y):\n",
    "    device = x.device\n",
    "    requires_grad = x.requires_grad\n",
    "    ctx = cls(device, requires_grad, x, y)\n",
    "    ret_data = ctx.forward(ctx, x, y)\n",
    "    ret = Tensor(ret_data, device, requires_grad)\n",
    "    ret._ctx = ctx\n",
    "    return ret\n",
    "  \n",
    "  def save_for_backward(self, x, y):\n",
    "    self.saved_tensors.extend(x, y)\n",
    "  \n",
    "  @property\n",
    "  def binary_op(self, x, y):\n",
    "    if self.device == 'CPU':\n",
    "      return binary_op_cpu\n",
    "    elif self.device == 'GPU':\n",
    "      return binary_op_gpu\n",
    "    \n",
    "class Mul(Function):\n",
    "  def forward(ctx, x, y):\n",
    "    ctx.save_for_backward(x, y)\n",
    "    ctx.binary_op('MUL', x, y)\n",
    "\n",
    "  def backward(ctx, grad_output):\n",
    "    x,y = ctx.saved_tensors\n",
    "    tmp = ctx.buffer(grad_output.shape)\n",
    "    # skipping for now\n",
    "\n",
    "class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
