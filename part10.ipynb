{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.tensor import Tensor\n",
    "\n",
    "a = Tensor([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to expand support for GPU in an elegant way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data, device=\"CPU\"):\n",
    "        self.data = self._move_data(data, device)\n",
    "\n",
    "    def _move_data(data, device):\n",
    "        if device == 'GPU':\n",
    "            return GPUBuffer(data)\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can define the GPUBuffer with opencl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "class GPUBuffer:\n",
    "    def __init__(self, data) -> None:\n",
    "        self.cl = cl.Buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to register all the methods defined in both CPU and GPU, we need to import them via `import ops_cpu; import ops_gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "class Mul(Function):\n",
    "  @staticmethod\n",
    "  def forward(ctx, x, y):\n",
    "    ctx.save_for_backward(x, y)\n",
    "    return x*y\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(ctx, grad_output):\n",
    "    x,y = ctx.saved_tensors\n",
    "    return unbroadcast(y*grad_output, x.shape), unbroadcast(x*grad_output, y.shape)\n",
    "register('mul', Mul)\n",
    "\n",
    "#GPU\n",
    "class Mul(Function):\n",
    "  @staticmethod\n",
    "  def forward(ctx, x, y):\n",
    "    ctx.save_for_backward(x, y)\n",
    "    return binary_op(ctx, 'a*b', x, y)\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(ctx, grad_output):\n",
    "    x,y = ctx.saved_tensors\n",
    "    grad_x = binary_op(ctx, 'a*b', y, grad_output)\n",
    "    grad_y = binary_op(ctx, 'a*b', x, grad_output)\n",
    "    return unbroadcast(ctx, grad_x, x.shape), unbroadcast(ctx, grad_y, y.shape),\n",
    "register('mul', Mul, device=Device.GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU operation is straightforward, but on the GPU, we "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
